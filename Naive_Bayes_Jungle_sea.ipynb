{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "64c1e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6e408e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(\"Data/image\")\n",
    "dataset=pd.DataFrame({'label':[],'R':[],'G':[],'B':[],'name':[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2113c762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j</td>\n",
       "      <td>76.636</td>\n",
       "      <td>104.799</td>\n",
       "      <td>44.681</td>\n",
       "      <td>j28.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j</td>\n",
       "      <td>31.138</td>\n",
       "      <td>59.272</td>\n",
       "      <td>35.637</td>\n",
       "      <td>j9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j</td>\n",
       "      <td>71.235</td>\n",
       "      <td>98.644</td>\n",
       "      <td>52.440</td>\n",
       "      <td>j1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j</td>\n",
       "      <td>77.520</td>\n",
       "      <td>86.574</td>\n",
       "      <td>64.969</td>\n",
       "      <td>j10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j</td>\n",
       "      <td>76.129</td>\n",
       "      <td>97.608</td>\n",
       "      <td>44.976</td>\n",
       "      <td>j11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>s</td>\n",
       "      <td>103.468</td>\n",
       "      <td>165.880</td>\n",
       "      <td>205.668</td>\n",
       "      <td>s5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>s</td>\n",
       "      <td>78.360</td>\n",
       "      <td>98.228</td>\n",
       "      <td>119.322</td>\n",
       "      <td>s6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>s</td>\n",
       "      <td>49.876</td>\n",
       "      <td>81.471</td>\n",
       "      <td>100.091</td>\n",
       "      <td>s7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>s</td>\n",
       "      <td>118.603</td>\n",
       "      <td>153.979</td>\n",
       "      <td>167.559</td>\n",
       "      <td>s8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>s</td>\n",
       "      <td>111.108</td>\n",
       "      <td>141.398</td>\n",
       "      <td>174.614</td>\n",
       "      <td>s9.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        R        G        B     name\n",
       "0      j   76.636  104.799   44.681  j28.jpg\n",
       "1      j   31.138   59.272   35.637   j9.jpg\n",
       "2      j   71.235   98.644   52.440   j1.jpg\n",
       "3      j   77.520   86.574   64.969  j10.jpg\n",
       "4      j   76.129   97.608   44.976  j11.jpg\n",
       "..   ...      ...      ...      ...      ...\n",
       "77     s  103.468  165.880  205.668   s5.jpg\n",
       "78     s   78.360   98.228  119.322   s6.jpg\n",
       "79     s   49.876   81.471  100.091   s7.jpg\n",
       "80     s  118.603  153.979  167.559   s8.jpg\n",
       "81     s  111.108  141.398  174.614   s9.jpg\n",
       "\n",
       "[82 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_colors(files):\n",
    "    shape=dataset.shape[0]\n",
    "    for j in range(len(files)):\n",
    "        img=cv.imread(\"Data/image/\"+files[j])\n",
    "        avgR = round(np.mean(img[:,:,2]),3)\n",
    "        avgG = round(np.mean(img[:,:,1]),3)\n",
    "        avgB = round(np.mean(img[:,:,0]),3)\n",
    "        dataset.loc[j+shape]=[files[j][0],avgR,avgG,avgB,files[j]]\n",
    "extract_colors(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "60256c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subFrame():\n",
    "    \"\"\"\n",
    "    we create a class to extract the training samples for each class and also\n",
    "    seperate our training set from our test set\n",
    "    we define three options, \n",
    "    one for classes spliting and preprocessing,\n",
    "    one for creatign 1vs rest naive bayes by combining the training samples of the two other classes\n",
    "    and one for global training set.\n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe,column=None,class_name=None,option=1,dataframe2=None):\n",
    "        if option==1:\n",
    "            self.name=class_name\n",
    "            self.dataframe=dataframe.loc[(dataframe[column]==class_name)]\n",
    "            #self.cleans()\n",
    "            #self.toNumeric()\n",
    "            #self.toKG()\n",
    "            #spliting sub dataframe to test set and data set\n",
    "            self.testset=self.dataframe.iloc[:round((self.dataframe.shape[0]/100)*30)]\n",
    "            self.dataframe=self.dataframe.iloc[round((self.dataframe.shape[0]/100)*30):]\n",
    "        elif option == 0 :\n",
    "            self.dataframe=pd.concat([dataframe2,dataframe],ignore_index=True)\n",
    "            self.trainset=None\n",
    "        elif option==2:\n",
    "            self.dataframe=dataframe\n",
    "            self.trainset=None\n",
    "            \n",
    "    def return_std(self):\n",
    "        #creating a std function for each feature of dataframe\n",
    "        self.std={};\n",
    "        for i in list(self.dataframe)[1:4]:\n",
    "            self.std[i]=round(self.dataframe[i].std(),3)\n",
    "        return self.std\n",
    "    def return_mean(self):\n",
    "        self.mean={};\n",
    "        for i in list(self.dataframe)[1:4]:\n",
    "            self.mean[i]=round(self.dataframe[i].mean(),3)\n",
    "        return self.mean\n",
    "    def toKG(self):\n",
    "        #converting body masses from g to kg to normalize the distribution of data\n",
    "        self.dataframe['body_mass_g']=self.dataframe['body_mass_g'].div(1000).round(1)\n",
    "    \n",
    "    def cleans(self):\n",
    "        \"\"\"\n",
    "        deleting empty rows per each subFrame\n",
    "        \n",
    "        \"\"\"\n",
    "        self.dataframe=self.dataframe[self.dataframe['body_mass_g']!='x']\n",
    "        \n",
    "    def toNumeric(self):\n",
    "        #converting string datas to numeric datas\n",
    "        for i in list(self.dataframe)[1:]:\n",
    "            self.dataframe[i]=pd.to_numeric(self.dataframe[i])\n",
    "            \n",
    "    def returnFrame(self):\n",
    "        return self.dataframe\n",
    "    def returnTest(self):\n",
    "        return self.testset\n",
    "    def set_total(self,total):\n",
    "        self.total=total\n",
    "    def p_wi(self):\n",
    "        return round(self.dataframe.shape[0]/self.total,6)\n",
    "    def p_xi_wi(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d9c47ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jungle=subFrame(dataset,column='label',class_name='j')\n",
    "sea=subFrame(dataset,column='label',class_name='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c41801f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jungle.set_total(148)\n",
    "sea.set_total(148)\n",
    "trainset=subFrame(jungle.returnFrame(),option=0,dataframe2=sea.returnFrame())\n",
    "testset=subFrame(jungle.returnTest(),option=0,dataframe2=sea.returnTest())\n",
    "trainset=trainset.returnFrame()\n",
    "testset=testset.returnFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "81a5a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(feature,class1:subFrame,label):\n",
    "    std=class1.return_std()[label];\n",
    "    mean=class1.return_mean()[label];\n",
    "    f_x=(1/(std*math.sqrt(2*math.pi)))*(np.e**(-(((feature-mean)**2)/(2*(std**2)))))\n",
    "    return f_x\n",
    "def posterior (feature_vector:list,class1:subFrame,class2:subFrame):\n",
    "    labels=list(dataset)[1:4]\n",
    "    f_xc1=[]\n",
    "    f_xc2=[]\n",
    "    px_w1=1\n",
    "    px_w2=1\n",
    "    for i in range(len(feature_vector)):\n",
    "        f_xc1.append(likelihood(feature_vector[i],class1,labels[i]))\n",
    "        f_xc2.append(likelihood(feature_vector[i],class2,labels[i]))\n",
    "    #print (f_xc1)\n",
    "    #print(f_xc2)\n",
    "    for i in range(len(feature_vector)):\n",
    "        px_w1=px_w1*f_xc1[i]\n",
    "        px_w2=px_w2*f_xc2[i]\n",
    "    #print (px_w1)\n",
    "    #print (px_w2)\n",
    "    posterior_w1=(px_w1*class1.p_wi())/((px_w1*class1.p_wi())+(px_w2*class2.p_wi()))\n",
    "    posterior_w2=(px_w2*class2.p_wi())/((px_w1*class1.p_wi())+(px_w2*class2.p_wi()))\n",
    "    return posterior_w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "19905b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "samle missclassified : s13.jpg\n",
      "samle missclassified : j19.jpg\n",
      "[[12  1]\n",
      " [ 1 11]]\n",
      "The accuracy 0.92\n",
      "The recall is : 0.9230769230769231\n",
      "The percision is : 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes_model(feature_vector:list,class1:subFrame,\n",
    "                     class2:subFrame,):\n",
    "    posteriors={}\n",
    "    posteriors['j']=posterior(feature_vector,class1,class2)\n",
    "    posteriors['s']=posterior(feature_vector,class2,class1)\n",
    "\n",
    "    lst=list(posteriors)\n",
    "    max=0\n",
    "    choice=''\n",
    "    for i in lst:\n",
    "        if posteriors[i]>max:\n",
    "            max=posteriors[i]\n",
    "            choice=i\n",
    "    return (choice,max)\n",
    "features=[]\n",
    "for i in range(testset.shape[0]):\n",
    "    features.append(testset.iloc[i])\n",
    "misses=0\n",
    "print (len(features))\n",
    "x11=0\n",
    "x12=0\n",
    "x21=0\n",
    "x22=0\n",
    "for i in features:\n",
    "    output=naive_bayes_model([i[1],i[2],i[3]],jungle,sea)\n",
    "    #print (\"answer :\",i[0])\n",
    "    #print (\"predict : \",output[0])\n",
    "    #print (\"========\\n\")\n",
    "    if output[0]!=i[0]:\n",
    "        misses+=1\n",
    "        print (\"samle missclassified : \"+i[4])\n",
    "        #print (\"increament\")\n",
    "    #print (output[0],i[0])\n",
    "    if i[0]=='j' and output[0]=='j':\n",
    "        x11=x11+1\n",
    "    elif i[0]=='j' and output[0]=='s':\n",
    "        x12=x12+1\n",
    "    elif i[0]=='s' and output[0]=='j':\n",
    "        x21=x21+1\n",
    "    elif i[0]=='s' and output[0]=='s':\n",
    "        x22=x22+1\n",
    "confusion_matrix=np.array([[x11,x12],[x21,x22]])\n",
    "print (confusion_matrix)\n",
    "print (\"The accuracy\", (testset.shape[0]-misses)/testset.shape[0])\n",
    "print (\"The recall is :\",confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[1][0]))\n",
    "print (\"The percision is :\",confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[0][1]))\n",
    "#print (sea.returnFrame().shape,jungle.returnFrame().shape)\n",
    "#print (testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738a3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac72ff2cdd95861d196cb7196018697b4b3312bd8660b15be55588a6279cbb17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
